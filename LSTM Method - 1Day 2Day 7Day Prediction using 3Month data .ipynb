{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQuCtyHUpR77"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.metrics import mean_absolute_percentage_error, r2_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse(y,t):\n",
        "    return np.sqrt(np.mean((y-t)**2))\n",
        "\n",
        "def mape(y_true,y_pred):\n",
        "  return mean_absolute_percentage_error(y_true, y_pred)\n",
        "\n",
        "def mse(y,t):\n",
        "    return np.mean((y-t)**2)"
      ],
      "metadata": {
        "id": "UX0J2vfoInxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df = pd.read_csv('GE.csv')\n",
        "df = pd.read_csv('Soil_20min_3M.csv')\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "h94pavGuyxFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dates = pd.to_datetime(df['Date_time']) #Seperating the Dates Columns\n",
        "#print(train_data_dates.tail(15)) #Print Last 15 dates"
      ],
      "metadata": {
        "id": "6LQ4pVsyy79o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_rqd = list(df)[1:11] #columns to be used for training the model\n",
        "print(cols_rqd) #['param1', 'param2', 'param3', 'param4', 'param5']"
      ],
      "metadata": {
        "id": "0VxBz-ChzAbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_training = df[cols_rqd].astype(float) #DF with only the training columns\n",
        "#print(df_training)"
      ],
      "metadata": {
        "id": "YOZvBG3bzCsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalizing the data as LSTM is sensitive to magnitude (due to sigmoid and tanh)\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(df_training)\n",
        "df_training_scaled = scaler.transform(df_training)"
      ],
      "metadata": {
        "id": "5T5W8Nd4zFtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#As required for LSTM networks, we require to reshape an input data into n_samples x timesteps x n_features.\n",
        "#In this example, the n_features is 5. We will make timesteps = 14 (past days data used for training).\n",
        "#Empty lists to be populated using formatted training data\n",
        "trainX = []\n",
        "trainY = []\n",
        "n_future = 72  # Number of days we want to look into the future based on the past days.\n",
        "n_past = 108   # Number of past days we want to use to predict the future."
      ],
      "metadata": {
        "id": "qqdgjrmHzH26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reformat input data into a shape: (n_samples x timesteps x n_features)\n",
        "#In my example, my df_training_scaled has a shape...\n",
        "#... refers to the number of data points and 5 refers to the columns (multi-variables).\n",
        "for i in range(n_past, len(df_training_scaled) - n_future +1):\n",
        "    trainX.append(df_training_scaled[i - n_past:i, 0:df_training.shape[1]])\n",
        "    trainY.append(df_training_scaled[i + n_future - 1:i + n_future, 2]) #0 represents the first col -- and this number is the column which goes to the Ytrain\n",
        "\n",
        "trainX, trainY = np.array(trainX), np.array(trainY)\n",
        "\n",
        "print('trainX shape == {}.'.format(trainX.shape))\n",
        "print('trainY shape == {}.'.format(trainY.shape))"
      ],
      "metadata": {
        "id": "u6gZ_sd_zKs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(df_training_scaled[24:,0])\n",
        "# print(df_training_scaled[24:,1])\n",
        "# print(df_training_scaled[24:,2])\n",
        "# print(df_training_scaled[24:,3])\n",
        "# print(df_training_scaled[24:,4])\n",
        "# print(df_training_scaled[24:,5])\n",
        "# print(df_training_scaled[24:,6])\n",
        "# print(df_training_scaled[24:,7])\n",
        "# print(df_training_scaled[24:,8])\n",
        "# print(df_training_scaled[24:,9])"
      ],
      "metadata": {
        "id": "aYeqH6arV8vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainX = trainX[-5240:]\n",
        "trainY = trainY[-5240:]"
      ],
      "metadata": {
        "id": "W3CnSMK8jbtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('trainX shape == {}.'.format(trainX.shape))\n",
        "print('trainY shape == {}.'.format(trainY.shape))"
      ],
      "metadata": {
        "id": "bW5YVA__lCJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainY)"
      ],
      "metadata": {
        "id": "9Vw9GkD2W6kR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainX.shape[1])\n",
        "print(trainX.shape[2])\n",
        "print(trainY.shape[1])"
      ],
      "metadata": {
        "id": "x4GTIrM4HnCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DF (Samples, Features)\n",
        "#Train_X (Samples - TimeStamp, TimeStamp, Features)\n",
        "#Train_Y (Samples - TimeStamp, Prediction)\n",
        "\n",
        "#The model predicts only single value, but #it needs multiple variables for making prediction.\n",
        "#i.e. we can only predict a single day after the training, the day after where the data ends.\n",
        "#To predict more days in future, we need all the input features which are not present, i.e. we would also be required to predict them.\n",
        "\n",
        "#Autoencoder Model Defined\n",
        "\n",
        "model = Sequential()\n",
        "#model.add(LSTM(128, activation='relu', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
        "model.add(LSTM(64, activation='tanh', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
        "model.add(LSTM(32, activation='tanh', return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(trainY.shape[1]))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()\n",
        "\n",
        "# fit the model\n",
        "history = model.fit(trainX, trainY, epochs=10, batch_size=10, validation_split=0.1, verbose=1)\n",
        "\n",
        "plt.plot(history.history['loss'], label='Training loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "5SUjd3HizN_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting the output\n",
        "\n",
        "#Remember that we can only predict one day in future as our model needs 5 variables\n",
        "#as inputs for prediction. We only have all 5 variables until the last day in our dataset.\n",
        "\n",
        "n_past = 108\n",
        "n_prediction = 72  #let us predict\n",
        "\n",
        "predict_period_dates = pd.date_range(list(train_data_dates)[-n_past], periods=n_prediction, freq='T').tolist()\n",
        "print(predict_period_dates)\n",
        "\n",
        "#Make prediction\n",
        "prediction = model.predict(trainX[-n_prediction:]) #shape = (n, 1) where n is the n_days_for_prediction\n",
        "\n",
        "\n",
        "#Inverse transformation to rescale the data to original range.\n",
        "#Number of features used for transform and inverse should be same.\n",
        "#Therefore, let us copy our values 5 times and discard them after inverse transform\n",
        "prediction_copies = np.repeat(prediction, df_training.shape[1], axis=-1)\n",
        "y_pred_future = scaler.inverse_transform(prediction_copies)[:,2] # THIS INVERSE IS INLINE WITH THE COLUMNT OT BE PREDICTED"
      ],
      "metadata": {
        "id": "b-04oVwezRDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forecast_dates = []\n",
        "for time_i in predict_period_dates:\n",
        "    forecast_dates.append(time_i.date())\n",
        "\n",
        "#df_forecast = pd.DataFrame({'Date':np.array(forecast_dates), 'Open':y_pred_future})\n",
        "df_forecast = pd.DataFrame({'Date_time':np.array(forecast_dates), 's_m_5':y_pred_future})\n",
        "df_forecast['Date_time']=pd.to_datetime(df_forecast['Date_time'])\n",
        "\n",
        "original = df[['Date_time', 's_m_5']]\n",
        "original['Date_time']=pd.to_datetime(original['Date_time'])\n",
        "original = original.loc[original['Date_time'] >= '2010-1-1']\n",
        "\n",
        "test1 = df_forecast.drop(['Date_time'], axis=1)\n",
        "#print(test1)\n",
        "test2 = original.iloc[-n_prediction:]\n",
        "test2 = test2.reset_index()\n",
        "test2 = test2.drop(['index'], axis=1)\n",
        "#print(test2)\n",
        "\n",
        "result = pd.concat([test2, test1], axis=1)\n",
        "sns.set(rc={'figure.figsize':(15,10)})\n",
        "plt.plot(result['Date_time'], result.iloc[:,1], label='s_m_5 (Original)')\n",
        "plt.plot(result['Date_time'], result.iloc[:,2], label='s_m_5 (Forecast)')\n",
        "#print(result)\n",
        "\n",
        "print(\"RMSE   :\",rmse(result.iloc[:,1],result.iloc[:,2]))\n",
        "print(\"MAPE   :\",mape(result.iloc[:,1],result.iloc[:,2]))\n",
        "print(\"MSE    :\",mse(result.iloc[:,1],result.iloc[:,2]))\n",
        "print(\"R2     :\",r2_score(result.iloc[:,1],result.iloc[:,2]))"
      ],
      "metadata": {
        "id": "hhCUHmOHTmEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting the output\n",
        "\n",
        "#Remember that we can only predict one day in future as our model needs 5 variables\n",
        "#as inputs for prediction. We only have all 5 variables until the last day in our dataset.\n",
        "\n",
        "n_past = 108\n",
        "n_prediction = 144  #let us predict\n",
        "\n",
        "predict_period_dates = pd.date_range(list(train_data_dates)[-n_past], periods=n_prediction, freq='T').tolist()\n",
        "print(predict_period_dates)\n",
        "\n",
        "#Make prediction\n",
        "prediction = model.predict(trainX[-n_prediction:]) #shape = (n, 1) where n is the n_days_for_prediction\n",
        "\n",
        "\n",
        "#Inverse transformation to rescale the data to original range.\n",
        "#Number of features used for transform and inverse should be same.\n",
        "#Therefore, let us copy our values 5 times and discard them after inverse transform\n",
        "prediction_copies = np.repeat(prediction, df_training.shape[1], axis=-1)\n",
        "y_pred_future = scaler.inverse_transform(prediction_copies)[:,2] # THIS INVERSE IS INLINE WITH THE COLUMNT OT BE PREDICTED"
      ],
      "metadata": {
        "id": "CHlLaBfO6-DH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forecast_dates = []\n",
        "for time_i in predict_period_dates:\n",
        "    forecast_dates.append(time_i.date())\n",
        "\n",
        "#df_forecast = pd.DataFrame({'Date':np.array(forecast_dates), 'Open':y_pred_future})\n",
        "df_forecast = pd.DataFrame({'Date_time':np.array(forecast_dates), 's_m_5':y_pred_future})\n",
        "df_forecast['Date_time']=pd.to_datetime(df_forecast['Date_time'])\n",
        "\n",
        "original = df[['Date_time', 's_m_5']]\n",
        "original['Date_time']=pd.to_datetime(original['Date_time'])\n",
        "original = original.loc[original['Date_time'] >= '2010-1-1']\n",
        "\n",
        "test1 = df_forecast.drop(['Date_time'], axis=1)\n",
        "#print(test1)\n",
        "test2 = original.iloc[-n_prediction:]\n",
        "test2 = test2.reset_index()\n",
        "test2 = test2.drop(['index'], axis=1)\n",
        "#print(test2)\n",
        "\n",
        "result = pd.concat([test2, test1], axis=1)\n",
        "sns.set(rc={'figure.figsize':(15,10)})\n",
        "plt.plot(result['Date_time'], result.iloc[:,1], label='s_m_5 (Original)')\n",
        "plt.plot(result['Date_time'], result.iloc[:,2], label='s_m_5 (Forecast)')\n",
        "#print(result)\n",
        "\n",
        "print(\"RMSE   :\",rmse(result.iloc[:,1],result.iloc[:,2]))\n",
        "print(\"MAPE   :\",mape(result.iloc[:,1],result.iloc[:,2]))\n",
        "print(\"MSE    :\",mse(result.iloc[:,1],result.iloc[:,2]))\n",
        "print(\"R2     :\",r2_score(result.iloc[:,1],result.iloc[:,2]))"
      ],
      "metadata": {
        "id": "A_rqLiig7CxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting the output\n",
        "\n",
        "#Remember that we can only predict one day in future as our model needs 5 variables\n",
        "#as inputs for prediction. We only have all 5 variables until the last day in our dataset.\n",
        "\n",
        "n_past = 108\n",
        "n_prediction = 504  #let us predict\n",
        "\n",
        "predict_period_dates = pd.date_range(list(train_data_dates)[-n_past], periods=n_prediction, freq='T').tolist()\n",
        "print(predict_period_dates)\n",
        "\n",
        "#Make prediction\n",
        "prediction = model.predict(trainX[-n_prediction:]) #shape = (n, 1) where n is the n_days_for_prediction\n",
        "\n",
        "\n",
        "#Inverse transformation to rescale the data to original range.\n",
        "#Number of features used for transform and inverse should be same.\n",
        "#Therefore, let us copy our values 5 times and discard them after inverse transform\n",
        "prediction_copies = np.repeat(prediction, df_training.shape[1], axis=-1)\n",
        "y_pred_future = scaler.inverse_transform(prediction_copies)[:,2] # THIS INVERSE IS INLINE WITH THE COLUMNT OT BE PREDICTED"
      ],
      "metadata": {
        "id": "oH7tR04E7UQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forecast_dates = []\n",
        "for time_i in predict_period_dates:\n",
        "    forecast_dates.append(time_i.date())\n",
        "\n",
        "#df_forecast = pd.DataFrame({'Date':np.array(forecast_dates), 'Open':y_pred_future})\n",
        "df_forecast = pd.DataFrame({'Date_time':np.array(forecast_dates), 's_m_5':y_pred_future})\n",
        "df_forecast['Date_time']=pd.to_datetime(df_forecast['Date_time'])\n",
        "\n",
        "original = df[['Date_time', 's_m_5']]\n",
        "original['Date_time']=pd.to_datetime(original['Date_time'])\n",
        "original = original.loc[original['Date_time'] >= '2010-1-1']\n",
        "\n",
        "test1 = df_forecast.drop(['Date_time'], axis=1)\n",
        "#print(test1)\n",
        "test2 = original.iloc[-n_prediction:]\n",
        "test2 = test2.reset_index()\n",
        "test2 = test2.drop(['index'], axis=1)\n",
        "#print(test2)\n",
        "\n",
        "result = pd.concat([test2, test1], axis=1)\n",
        "sns.set(rc={'figure.figsize':(15,10)})\n",
        "plt.plot(result['Date_time'], result.iloc[:,1], label='s_m_5 (Original)')\n",
        "plt.plot(result['Date_time'], result.iloc[:,2], label='s_m_5 (Forecast)')\n",
        "#print(result)\n",
        "\n",
        "print(\"RMSE   :\",rmse(result.iloc[:,1],result.iloc[:,2]))\n",
        "print(\"MAPE   :\",mape(result.iloc[:,1],result.iloc[:,2]))\n",
        "print(\"MSE    :\",mse(result.iloc[:,1],result.iloc[:,2]))\n",
        "print(\"R2     :\",r2_score(result.iloc[:,1],result.iloc[:,2]))"
      ],
      "metadata": {
        "id": "c6U5u_gD7VWW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}